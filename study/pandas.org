#+TITLE: Pandas 入门

* 介绍

如果用 python 的列表和字典来作比较, 那么可以说 Numpy 是列表形式的，没有数值标签，而 Pandas 就是字典形式。Pandas 是基于 Numpy 构建的，让 Numpy 为中心的应用变得更加简单。如果用 python 的列表和字典来作比较, 那么可以说 Numpy 是列表形式的，没有数值标签，而 Pandas 就是字典形式。Pandas 是基于 Numpy 构建的，让 Numpy 为中心的应用变得更加简单。

** 两大主要数据结构： =Series= 和 =DataFrame=

*** =Series=

#+begin_src python
import pandas as pd
import numpy as np


s = pd.Series([1, 3, 6, np.nan, 44, 1])
print(s)
"""
0     1.0
1     3.0
2     6.0
3     NaN
4    44.0
5     1.0
dtype: float64
"""
#+end_src

=Series= 的字符串表现为索引在左，值在右。默认是 0 到 N-1 的索引。
*** =DataFrame=

=DataFrame= 是一个表格型的数据结构，它包含有一组有序的列，每列可以是不同的值类型（数值，字符串，布尔值等）。 =DataFrame= 既有行索引也有列索引， 它可以被看做由 =Series= 组成的大字典。

#+begin_src python
dates = pd.date_range('20160101',periods=6)
df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=['a','b','c','d'])

print(df)
"""
                   a         b         c         d
2016-01-01 -0.234008 -0.487559  0.128086 -0.748150
2016-01-02  0.476546 -1.389383  1.590171  1.273469
2016-01-03  1.367207  0.460478 -0.137619  1.095721
2016-01-04 -0.770324  0.057975  0.678876 -0.833393
2016-01-05  0.445564  0.022115  0.061996  0.159976
2016-01-06  0.129173 -0.747147  0.673259 -0.306566
"""
#+end_src

我们可以根据每一个不同的索引来挑选数据, 比如挑选 =b= 的元素:

#+begin_src python
print(df['b'])
"""
2016-01-01   -0.487559
2016-01-02   -1.389383
2016-01-03    0.460478
2016-01-04    0.057975
2016-01-05    0.022115
2016-01-06   -0.747147
Freq: D, Name: b, dtype: float64
"""
#+end_src

我们在创建一组没有给定行标签和列标签的数据 =df1=:

#+begin_src python
df1 = pd.DataFrame(np.arange(12).reshape((3,4)))
print(df1)

"""
   0  1   2   3
0  0  1   2   3
1  4  5   6   7
2  8  9  10  11
"""
#+end_src

这样,他就会采取默认的从 0 开始 index. 还有一种生成 =df= 的方法, 如下 =df2=:

#+begin_src python
df2 = pd.DataFrame({'A' : 1.,
                    'B' : pd.Timestamp('20130102'),
                    'C' : pd.Series(1,index=list(range(4)),dtype='float32'),
                    'D' : np.array([3] * 4,dtype='int32'),
                    'E' : pd.Categorical(["test","train","test","train"]),
                    'F' : 'foo'})

print(df2)

"""
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo
"""
#+end_src

这种方法能对每一列的数据进行特殊对待. 如果想要查看数据中的类型, 我们可以用 =dtype= 这个属性:

#+begin_src python
print(df2.dtypes)

"""
df2.dtypes
A           float64
B    datetime64[ns]
C           float32
D             int32
E          category
F            object
dtype: object
"""
#+end_src

如果想看对列的序号：

#+begin_src python
print(df2.index)

"""
Int64Index([0, 1, 2, 3], dtype='int64')
"""
#+end_src

同样，每种数据的名称也能看到：

#+begin_src python
print(df2.columns)

"""
Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')
"""
#+end_src

如果只想看所有 =df2= 的值：

#+begin_src python
print(df2.values)
"""
[[1.0 Timestamp('2013-01-02 00:00:00') 1.0 3 'test' 'foo']
 [1.0 Timestamp('2013-01-02 00:00:00') 1.0 3 'train' 'foo']
 [1.0 Timestamp('2013-01-02 00:00:00') 1.0 3 'test' 'foo']
 [1.0 Timestamp('2013-01-02 00:00:00') 1.0 3 'train' 'foo']]
"""
#+end_src

想知道数据的总结，可以用 =describe()=：

#+begin_src python
print(df2.describe())
"""
         A    C    D
count  4.0  4.0  4.0
mean   1.0  1.0  3.0
std    0.0  0.0  0.0
min    1.0  1.0  3.0
25%    1.0  1.0  3.0
50%    1.0  1.0  3.0
75%    1.0  1.0  3.0
max    1.0  1.0  3.0
"""
#+end_src

如果想翻转数据， =transpose= ：

#+begin_src python
print(df2.T)
"""
                     0                    1                    2                    3
A                  1.0                  1.0                  1.0                  1.0
B  2013-01-02 00:00:00  2013-01-02 00:00:00  2013-01-02 00:00:00  2013-01-02 00:00:00
C                  1.0                  1.0                  1.0                  1.0
D                    3                    3                    3                    3
E                 test                train                 test                train
F                  foo                  foo                  foo                  foo
"""
#+end_src

如果想对数据的 =index= 进行排序并输出:

#+begin_src python
print(df2.sort_index(axis=1, ascending=False))

"""
     F      E  D    C          B    A
0  foo   test  3  1.0 2013-01-02  1.0
1  foo  train  3  1.0 2013-01-02  1.0
2  foo   test  3  1.0 2013-01-02  1.0
3  foo  train  3  1.0 2013-01-02  1.0
"""
#+end_src

如果是对数据值进行排序输出：

#+begin_src python
print(df2.sort_values(by='B'))

"""
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo
"""
#+end_src
* 数据筛选

我们事先定义一个数据：

#+begin_src python
dates = pd.date_range('20130101', periods=6)
df = pd.DataFrame(np.arange(24).reshape(6, 4), index=dates, columns=['A', 'B', 'C', 'D'])
print(df)
"""
             A   B   C   D
2013-01-01   0   1   2   3
2013-01-02   4   5   6   7
2013-01-03   8   9  10  11
2013-01-04  12  13  14  15
2013-01-05  16  17  18  19
2013-01-06  20  21  22  23
"""
#+end_src

** 行列筛选

如果我们想选取某一列的数据，其实很简单，下面两种方法是一样的：

#+begin_src python
print(df['A'])
print(df.A)

"""
2013-01-01     0
2013-01-02     4
2013-01-03     8
2013-01-04    12
2013-01-05    16
2013-01-06    20
Freq: D, Name: A, dtype: int64
"""
#+end_src

当我们想要选择其中一行时：

#+begin_src python
print(df.loc['2013-01'])

"""
A    0
B    1
C    2
D    3
Name: 2013-01-01 00:00:00, dtype: int64
"""
#+end_src

但如果我们要跨多行或多列：

#+begin_src python
print(df[0:3])
print(df['20130102': '20130104'])
"""
            A  B   C   D
2013-01-01  0  1   2   3
2013-01-02  4  5   6   7
2013-01-03  8  9  10  11
             A   B   C   D
2013-01-02   4   5   6   7
2013-01-03   8   9  10  11
2013-01-04  12  13  14  15
"""
#+end_src

** 根据标签筛选

=loc= 可以让我们使用标签来选择数据，上面我们展示过了一部分。

#+begin_src python
print(df.loc[:, ['A', 'B']])
print(df.loc['20130102', ['A', 'B']])
#+end_src

上面都是选取某某行的某某列。

** 根据序列筛选

使用 =iloc= 可以根据位置截取数据。

#+begin_src python
print(df.iloc[3, 1])
print(df.iloc[3:5, 1:3])
print(df.iloc[[1, 3, 5], 1:3])
#+end_src

** 混合模式

我们可以混合使用以上两种方法。

#+begin_src python
print(df.iloc[:3].loc[:, 'A':'C'])
#+end_src

** 条件筛选

#+begin_src python
print(df[df.A > 8])
#+end_src
* 数据设置

#+begin_src python
dates = pd.date_range('20130101', periods=6)
df = pd.DataFrame(np.arange(24).reshape((6, 4), index=dates, columns=['A', 'B', 'C', 'D']))

"""
             A   B   C   D
2013-01-01   0   1   2   3
2013-01-02   4   5   6   7
2013-01-03   8   9  10  11
2013-01-04  12  13  14  15
2013-01-05  16  17  18  19
2013-01-06  20  21  22  23
"""
#+end_src

** 选取位置设置数据

利用之前数据筛选的知识，我们可以选取位置进行替换：

#+begin_src python
df.iloc[2, 2] = 111
df.loc['20130101', 'B'] = 222
df.B[df.A > 4] = 0
df['F'] = np.nan
#+end_src
** 添加数据

我们可以加上一列长度对齐的 =Series= 序列。

#+begin_src python
df['E'] = pd.Series([1, 2, 3, 4, 5, 6],, index=pd.date_range('20130101', periods=6))
#+end_src
* 处理丢失数据

#+begin_src python
dates = pd.date_range('20130101', periods=6)
df = pd.DataFrame(np.arange(24).reshape((6,4)),index=dates, columns=['A','B','C','D'])
df.iloc[0,1] = np.nan
df.iloc[1,2] = np.nan
"""
             A     B     C   D
2013-01-01   0   NaN   2.0   3
2013-01-02   4   5.0   NaN   7
2013-01-03   8   9.0  10.0  11
2013-01-04  12  13.0  14.0  15
2013-01-05  16  17.0  18.0  19
2013-01-06  20  21.0  22.0  23
"""
#+end_src

** =pd.isnull()=

判断是否有缺失数据 =NaN= ， =True= 表示缺失数据。

#+begin_src python
df.isnull()
"""
                A      B      C      D
2013-01-01  False   True  False  False
2013-01-02  False  False   True  False
2013-01-03  False  False  False  False
2013-01-04  False  False  False  False
2013-01-05  False  False  False  False
2013-01-06  False  False  False  False
"""
#+end_src

检测数据中是否存在 =NaN= ，如果存在就返回 =True= 。

#+begin_src python
np.any(df.isnull()) == True
#+end_src

** =pd.dropna()= 和 =pd.fillna()=

=pd.dropna()= 可以直接去除带有 =NaN= 的行或列。

#+begin_src python
df.dropna(
    axis = 0, # 0: 对行，1: 对列
    how='any' # 'any': 只要存在 NaN 就去除， 'all'：必须全部都是 NaN 才去除
)
#+end_src

=pd.fillna()=

将 =NaN= 的值用其他值代替，比如代替成 0 。

#+begin_src python
df.fillna(value=0)
#+end_src
* 导入导出

** 导入

#+begin_src python
data = pd.read_pickle('student.pickle')
data = pd.read_csv('student.csv')
data = pd.read_excel('student.xlsx')
#+end_src

** 导出

#+begin_src python
data.to_pickle('student.pickle')
data.to_csv('student.csv')
data.to_excel('student.xlsx')
#+end_src
* 合并 =concat=

#+begin_src python
df1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'])
df2 = pd.DataFrame(np.ones((3,4))*1, columns=['a','b','c','d'])
df3 = pd.DataFrame(np.ones((3,4))*2, columns=['a','b','c','d'])
s1 = pd.Series([1, 2, 3, 4], columns=['a', 'b', 'c', 'd'])

res = pd.concat(
    [df1, df2, df3], # 合并数据
    axis=0, # 0: 纵向合并 1：横向合并
    index_ignore=True, # 默认 False ，是否重置 index
    join='inner' # 合并方式，默认 'outer'，外连接，取索引并集，内连接取索引交集
)
res = df1.append(
    [df2, df3], # 合并数据，可以是 DataFrame ，也可以是 Series 。
    ignore_index=True
)
#+end_src
* 合并 =merge=

#+begin_src python
left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],
                             'A': ['A0', 'A1', 'A2', 'A3'],
                             'B': ['B0', 'B1', 'B2', 'B3']})
right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],
                              'C': ['C0', 'C1', 'C2', 'C3'],
                              'D': ['D0', 'D1', 'D2', 'D3']})
# 按键值进行简单合并
print(pd.merge(left, right, on='key'))
#+end_src

#+begin_src python
left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],
                      'key2': ['K0', 'K1', 'K0', 'K1'],
                      'A': ['A0', 'A1', 'A2', 'A3'],
                      'B': ['B0', 'B1', 'B2', 'B3']})
right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],
                       'key2': ['K0', 'K0', 'K0', 'K0'],
                       'C': ['C0', 'C1', 'C2', 'C3'],
                       'D': ['D0', 'D1', 'D2', 'D3']})

# 多键值合并
print(pd.merge(
    left, right, # 需要合并的 df
    on=['key1', 'key2'], # 按 key1-key2 做类分
    how='inner')) # inner outer right left
#+end_src

#+begin_src python
df1 = pd.DataFrame({'col1':[0,1], 'col_left':['a','b']})
df2 = pd.DataFrame({'col1':[1,2,2],'col_right':[2,2,2]})

print(pd.merge(df1, df2, on='col1', how='outer', indicator=True)) # indicator为 True 将会展示合并方式。
'''
   col1 col_left  col_right      _merge
0     0        a        NaN   left_only
1     1        b        2.0        both
2     2      NaN        2.0  right_only
3     2      NaN        2.0  right_only
'''
print(pd.merge(df1, df2, on='col2', how='outer', indicator='indicator_column'))
'''
   col1 col_left  col_right indicator_column
0     0        a        NaN        left_only
1     1        b        2.0             both
2     2      NaN        2.0       right_only
3     2      NaN        2.0       right_only
'''
#+end_src

#+begin_src python
left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],
                     'B': ['B0', 'B1', 'B2']},
                     index=['K0', 'K1', 'K2'])
right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],
                      'D': ['D0', 'D2', 'D3']},
                     index=['K0', 'K2', 'K3'])

print(pd.merge(left, right, left_index = True, right_index = True, how='outer'))

print(pd.merge(left, right, left_index = True, right_index = True, how='inner'))
#+end_src

去除重复。

#+begin_src python
#定义资料集
boys = pd.DataFrame({'k': ['K0', 'K1', 'K2'], 'age': [1, 2, 3]})
girls = pd.DataFrame({'k': ['K0', 'K0', 'K3'], 'age': [4, 5, 6]})

#使用suffixes解决overlapping的问题
res = pd.merge(boys, girls, on='k', suffixes=['_boy', '_girl'], how='inner')
print(res)
#    age_boy   k  age_girl
# 0        1  K0         4
# 1        1  K0         5
#+end_src
